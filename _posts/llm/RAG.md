---
title: RAG
tags:
  - AI
category:
  - AI
author: bsyonline
lede: 没有摘要
date: 2018-05-28 15:32:21
thumbnail:
---


### 向量

向量是同时包含**大小**和**方向**的量。

![[向量.png]]

#### 向量的运算

##### 加

假设有两个向量 $\vec{AB}$ 和 $\vec{CD}$ ，则 $\vec{AB}$ + $\vec{CD}$ 

三角形法则：**首尾相连**，将任意一个向量的起点，**平移**到另一个向量的终点处。

![[向量三角形法则.png]]


平行四边形法则：**起点相连**，将两个向量的起点平移到一起，做出平行四边形。

![[向量平行四边形法则.png]]

##### 减

假设有两个向量 $\vec{AB}$ 和 $\vec{CD}$ 

方法一：$\vec{AB}$ + $\vec{CD}$ = $\vec{AB} + \vec{(-CD)}$ 

![[向量的减法1.png]]
方法二：减向量指向被减向量。

![[向量的减法2.png]]

##### 数乘

向量的数乘将得到一个新向量，方向不变，长度是原向量的 n 倍。

##### 点乘（内积）

两个向量对应位置上的值相乘再相加的操作，其结果即为点积。

假设有两个向量 $\vec{AB}=\begin{bmatrix} x_1 \\ y_1 \end{bmatrix}$ 和 $\vec{CD}=\begin{bmatrix} x_2 \\ y_2 \end{bmatrix}$ ，则 $x_1 \cdot x_2 + y_1 \cdot y_2$ 。

从几何角度看，点积是两个向量的长度与它们夹角余弦的积。

![[向量点乘.png]]

##### 叉乘（外积）

**叉乘（Cross Product）** 又称**向量积**（Vector Product）。




### Embedding

Embedding 是将高维的、离散的、非结构化的数据转换为低维的、连续的向量的一种技术。因为计算机无法直接理解现实的事物，为了让计算机能够理解，我们就需要将现实的事物描述成一组向量，Embedding 就是现实世界和计算机之间的桥梁。现实世界中越相似的事物在转换成向量之后，它们的位置也越接近。

Embedding 之后的向量不仅满足向量的数学性质（可计算距离、相似度），还承载了现实事物之间的关系。

#### Embedding 的过程

以文本翻译为例，“who am I” 翻译成“我是谁”。首先对原始文本进行清洗，去除一些无意义的符号同时增加一些有特殊含义的字符，比如 `<sos>who am I<eos><pad><pad>...<pad>` 。

在通过分词器根据一个词表 Vocab 将文本转化成一组向量。


#### Embedding 模型是怎么训练出来的




### 向量数据库

向量数据库就是用来存储和查询向量的数据库。


### 索引

将分片的文本embedding成向量存到数据库的过程。

### 召回

搜索与用户问题相关的文本的过程。

### 重排


### 生成


