---
title: 02_模型并行初始化
tags:
  - llm
category: 
author: bsyonline
lede: 没有摘要
date: 2019-05-25 12:01:20
thumbnail:
---


框架执行的入口是 `megatron/training/training.py` 的 `pretrain()` 。

```python
def pretrain(  
    train_valid_test_dataset_provider,  
    model_provider,  
    model_type,  
    forward_step_func,  
    process_non_loss_data_func=None,  
    extra_args_provider=None,  
    args_defaults={},  
    get_embedding_ranks=None,  
    get_position_embedding_ranks=None,  
    non_loss_data_func=None,  
):
	...
```


pretrain 分为 4 步：
1. 初始化 Megatron 。
2. 使用 `model_provider` 设置 model、optimizer 和 lr schedule 。
3. 使用 `train_val_test_data_provider` 获取 `train/val/test` 数据集。
4. 使用 `forward_step_func` 训练模型。


### 初始化 Megatron

初始化方法 initialize_megatron 在 `megatron/training/initialize.py` ，分为3步：
1. 设置全局变量。
2. 初始化分布式。
3. 设置 autoresume 和随机种子。

```python
def initialize_megatron(  
    extra_args_provider=None,  
    args_defaults={},  
    ignore_unknown_args=False,  
    allow_no_cuda=False,  
    skip_mpu_initialization=False,  
    get_embedding_ranks=None,  
    get_position_embedding_ranks=None,  
):
	...
	# Parse arguments
	args = parse_args(extra_args_provider, ignore_unknown_args)
	...
	# set global args, build tokenizer, and set adlr-autoresume,
	# tensorboard-writer, and timers.
	set_global_variables(args)
	...
	# Megatron's MPU is the master. Complete initialization right away.
	finish_mpu_init()
	# Autoresume.
	_init_autoresume()
	# Compile dependencies.
	_compile_dependencies()
	...
```

在 `finish_mpu_init()` 中会进行模型并行初始化。在初始化的时候会创建不通类型的分组，以双机 16 卡为例，tp=4，pp=2，dp = 16 / (4 * 2 * 1) = 2 时分组如下：

```python
dp_ranks=[[0, 4], [1, 5], [2, 6], [3, 7], [8, 12], [9, 13], [10, 14], [11, 15]]
dp_cp_ranks=[[0, 4], [1, 5], [2, 6], [3, 7], [8, 12], [9, 13], [10, 14], [11, 15]]
cp_ranks=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]
tp_pp_ranks=[[0, 1, 2, 3, 8, 9, 10, 11], [4, 5, 6, 7, 12, 13, 14, 15]]
tp_ep_pp_ranks=[[0, 1, 2, 3, 8, 9, 10, 11], [4, 5, 6, 7, 12, 13, 14, 15]]
tp_ranks=[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15]]
pp_ranks=[[0, 8], [1, 9], [2, 10], [3, 11], [4, 12], [5, 13], [6, 14], [7, 15]]
tp_dp_cp_ranks=[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]
tp_dp_ranks=[[0, 1, 2, 3, 4, 5, 6, 7], [8, 9, 10, 11, 12, 13, 14, 15]]
tp_cp_ranks=[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15]]
tp_ep_ranks=[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15]]
ep_ranks=[[0], [1], [2], [3], [4], [5], [6], [7], [8], [9], [10], [11], [12], [13], [14], [15]]
dp_ranks=[[0, 4], [1, 5], [2, 6], [3, 7], [8, 12], [9, 13], [10, 14], [11, 15]]
dp_cp_ranks=[[0, 4], [1, 5], [2, 6], [3, 7], [8, 12], [9, 13], [10, 14], [11, 15]]
```

由于有些并行度是 1 ，所以有些分组是重复的，比如 cp=1 所以 tp_dp_cp_ranks 和 tp_dp_ranks 是一样的。我们主要来看 tp pp dp 的分组。由于 dp 为 2 ，每个 dp 组中有 2 个 rank ，所以是数据并行分组为 `[[0, 4], [1, 5], [2, 6], [3, 7], [8, 12], [9, 13], [10, 14], [11, 15]]`。tp = 4 每个组有 4 个 rank ，所以模型并行分组为 `[[0, 1, 2, 3], [4, 5, 6, 7], [8, 9, 10, 11], [12, 13, 14, 15]]` 。pp = 2 每个组有 2 个 rank ，所以流水线并行分组为 `[[0, 8], [1, 9], [2, 10], [3, 11], [4, 12], [5, 13], [6, 14], [7, 15]]` 。



### 加载模型

### 加载数据

流水线并行中数据流向为：
1. **第一个 stage**：
    - 加载原始数据
    - 处理输入嵌入
    - 将中间激活值传递给下一阶段
2. **中间 stages**：
    - 接收上一阶段的激活值
    - 执行分配的网络层计算
    - 将结果传递给下一阶段
3. **最后一个 stage**：
    - 接收前一阶段的激活值
    - 执行最终的网络层计算
    - 使用本地存储的标签数据计算损失
    - 初始化反向传播


### 训练


调用 train_step 函数执行实际的前向和后向传播


1. **混合精度训练支持**：通过 loss scale 处理和梯度检查来稳定混合精度训练
2. **分布式训练优化**：使用前向预钩子和参数同步函数优化分布式训练通信
3. **动态批量大小**：支持在训练过程中动态调整批量大小
4. 1. **灵活的检查点策略**：支持同步和异步检查点保存
5. 1. **容错机制**：通过状态机和检测机制处理训练故障